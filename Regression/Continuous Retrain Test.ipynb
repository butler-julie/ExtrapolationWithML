{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.linear_model.ridge module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "# THIRD-PARTY IMPORTS\n",
    "# For array management and some calculations\n",
    "import numpy as np\n",
    "# Used for timing the running of codes\n",
    "import time\n",
    "# Ridge Methods\n",
    "from sklearn.linear_model.ridge import Ridge\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# Prevents extraneous printing of messages during a grid search\n",
    "import warnings\n",
    "# For making parameter lists in hyperparameter tuning\n",
    "from itertools import product\n",
    "\n",
    "# LOCAL IMPORTS\n",
    "from RegressionSupport import *\n",
    "\n",
    "#############################\n",
    "# IMPORTS\n",
    "#############################\n",
    "# SYSTEM LEVEL IMPORTS\n",
    "# Import files from other directories\n",
    "import sys\n",
    "\n",
    "# THIRD-PARTY IMPORTS\n",
    "# For array handling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LOCAL IMPORTS\n",
    "# Linear regression codes\n",
    "from LinearRegression import LinearRegressionAnalysis\n",
    "# Ridge regression codes\n",
    "from RidgeRegression import RidgeRegressionAnalysis\n",
    "# Kernel ridge regression codes\n",
    "from KernelRidgeRegression import KernelRidgeRegressionAnalysis\n",
    "# Support methods, including graphing capabilities\n",
    "from RegressionSupport import *\n",
    "# Changing the import directory\n",
    "sys.path.append('../DataSets/')\n",
    "# Data sets (mostly physics related)\n",
    "from DataSets import *\n",
    "from ElectronGas import *\n",
    "from NuclearBindingEnergy import *\n",
    "from EquationOfState import *\n",
    "\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tot, y_tot, design_matrix = EquationOfState()\n",
    "#print(len(X_tot))\n",
    "#X_tot = np.arange(1, 100)\n",
    "#y_tot = X_tot ** 3\n",
    "\n",
    "training_dim = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# KNOWN DATA SEQ (SEQUENTIAL)\n",
    "#############################\n",
    "def sequential (X_train, y_train, y_tot, training_dim, params, verbose=True, seq=2):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            X_train (a list or numpy array): the x component of the training data\n",
    "            y_train (a list or numpy array): the y component of the training data\n",
    "            y_tot (a list of numpy array): the total set of data points (training plus validation)\n",
    "            training_dim (an int): the size of the traing data (i.e. the number of points\n",
    "                from y_tot that are used in the training)\n",
    "            params (a list): contains the parameters of the ridge regression \n",
    "                algorithm.  In order: normalize, alpha, and solver.\n",
    "            verbose (a boolean): True case: prints the MSE score of the extrapolated data\n",
    "                when compared to the true data.\n",
    "        Returns:\n",
    "            y_return (a list): the known points and the extrapolated data points\n",
    "            Unnamed (a float): the MSE error between the true data and the predicted\n",
    "                data\n",
    "        Performs ridge regression on the given data set using the given parameters\n",
    "        and then extrapolates data points to get a complete data set.  Prints the MSE \n",
    "        score of the extrapolated data set compared to the true data set if desired and\n",
    "        then returns the extrapolated data set.\n",
    "\n",
    "    \"\"\"\n",
    "    # To ensure that all parameters are present \n",
    "    assert len(params)==3\n",
    "\n",
    "    # Set up the model\n",
    "    r = Ridge (normalize = params[0], alpha = params[1], solver = params[2])    \n",
    "\n",
    "    # Fit the model to the training data\n",
    "    r.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict the points in the validation set\n",
    "    y_return = y_tot[:training_dim].tolist()\n",
    "    plt.scatter (X_tot[:training_dim], y_return)\n",
    "    next_input = [[y_return[-2], y_return[-1]]]\n",
    "    last = y_return[-1]\n",
    "    i = training_dim\n",
    "    while len(y_return) < len(y_tot):\n",
    "        try:\n",
    "            next = r.predict(next_input)\n",
    "        except:\n",
    "            print ('Overflow encountered on predicton')\n",
    "            return None, 1e10\n",
    "        y_return.append(next[0])\n",
    "        plt.scatter(X_tot[i], y_return[-1])\n",
    "        plt.pause(1.0)\n",
    "        i = i + 1\n",
    "        next_input =[[last, next[0]]]\n",
    "        last = next[0]\n",
    "\n",
    "    # Print the MSE error if needed\n",
    "    if verbose:  \n",
    "        print ('RIDGE MSE VALUE: ', mse(y_tot, y_return))\n",
    "\n",
    "    # Return the predicted points and the MSE error\n",
    "    return y_return, mse(y_tot, y_return)\n",
    "\n",
    "#############################\n",
    "# KNOWN DATA CR SEQ (CONTINUOUS RETRAIN, SEQUENTIAL)\n",
    "#############################\n",
    "def sequential_autoregression (X_train, y_train, y_tot,\n",
    "    training_dim, params, verbose, seq=2):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            X_train (a list or numpy array): the x component of the training data\n",
    "            y_train (a list or numpy array): the y component of the training data\n",
    "            y_tot (a list of numpy array): the total set of data points\n",
    "            training_dim (an int): the size of the traing data (i.e. the number of points\n",
    "                from y_tot that are used in the training)\n",
    "            params (a list): contains the parameters of the ridge regression \n",
    "                algorithm.  In order: normalize, alpha, and solver.\n",
    "            verbose (a boolean): True case: prints the MSE score of the extrapolated data\n",
    "                when compared to the true data.\n",
    "            seq (an int): the length of the series to use in the time series formatting (default \n",
    "                value is 2)    \n",
    "        Returns:\n",
    "            y_return (a list): the known points and the extrapolated data points\n",
    "            Unnamed (a float): the MSE error between the true data and the predicted\n",
    "                data\n",
    "        Performs ridge regression on the given data set using the given parameters\n",
    "        and then extrapolates data points to get a complete data set. Ridge \n",
    "        regression is performed after each point is extrapolated to hopefully decrease \n",
    "        the average MSE score.  Prints the MSE score of the extrapolated data set \n",
    "        compared to the true data set if desired and then returns the extrapolated data\n",
    "        set.\n",
    "\n",
    "    \"\"\"\n",
    "    # To ensure that all parameters are present\n",
    "    assert len(params)==3\n",
    "\n",
    "    # Set up the model\n",
    "    r = Ridge (normalize = params[0], alpha = params[1], solver = params[2])\n",
    "\n",
    "    # Add the known training data to the predicted points list\n",
    "    y_return = y_tot[:training_dim].tolist()\n",
    "    plt.scatter (X_tot[:training_dim], y_return)\n",
    "    i = training_dim\n",
    "    plt.pause(1.0)\n",
    "    # While the length of the predicted points list is less than the total number of \n",
    "    # needed points\n",
    "    while len(y_return) < len(y_tot):\n",
    "        # Ensure that there are enough points the the predicted points list to be \n",
    "        # properly formatted.  Re-fitting the model only occurs when there are enough \n",
    "        # data points for the data to be properly formatted\n",
    "        if len(y_return) % seq == 0:\n",
    "            print (\"RETRAIN\")\n",
    "            # Format the data\n",
    "            X_train, y_train = time_series_data(y_return)\n",
    "            print(len(y_train))\n",
    "            # Fit the model\n",
    "            r.fit(X_train, y_train)\n",
    "            print(r)\n",
    "        # Predict the next point in the data set and add it to the list\n",
    "        next_input = [[y_return[-2], y_return[-1]]]    \n",
    "        next = r.predict(next_input)    \n",
    "        y_return.append(next[0])\n",
    "        plt.scatter(X_tot[i], y_return[-1])\n",
    "        i = i + 1\n",
    "        plt.pause(1.0)\n",
    "\n",
    "    # Print the MSE error if needed\n",
    "    if verbose:\n",
    "        print ('RIDGE CONTINUOUS RETRAIN MSE VALUE: ', mse(y_tot, y_return))\n",
    "\n",
    "    # Return the predicted list\n",
    "    return y_return, mse(y_tot, y_return)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [True, 0, 'auto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = time_series_data (y_tot[:training_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE MSE VALUE:  4497.778193496928\n"
     ]
    }
   ],
   "source": [
    "y1, mse1 = sequential(X_train, y_train, y_tot, training_dim, params, True, seq=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETRAIN\n",
      "78\n",
      "Ridge(alpha=0, normalize=True)\n",
      "RETRAIN\n",
      "80\n",
      "Ridge(alpha=0, normalize=True)\n",
      "RETRAIN\n",
      "82\n",
      "Ridge(alpha=0, normalize=True)\n",
      "RETRAIN\n",
      "84\n",
      "Ridge(alpha=0, normalize=True)\n",
      "RETRAIN\n",
      "86\n",
      "Ridge(alpha=0, normalize=True)\n",
      "RIDGE CONTINUOUS RETRAIN MSE VALUE:  4497.778193490564\n"
     ]
    }
   ],
   "source": [
    "y2, mse2 = sequential_autoregression(X_train, y_train, y_tot, training_dim, params, True, seq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQUENTIAL ONLY:  4497.778193496928\n",
      "SEQUENTIAL AUTOREGRESSION:  4497.778193490564\n"
     ]
    }
   ],
   "source": [
    "print ('SEQUENTIAL ONLY: ', mse1)\n",
    "print ('SEQUENTIAL AUTOREGRESSION: ', mse2)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x105cd3dd8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(X_tot, y_tot, label=\"true\")\n",
    "plt.plot(X_tot, y1, label=\"seq\", linewidth=4)\n",
    "plt.plot(X_tot, y2, label='seq_auto')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5093046419339269\n"
     ]
    }
   ],
   "source": [
    "print (mse1/y_tot[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3333333333333335e-05\n"
     ]
    }
   ],
   "source": [
    "print(1e-5/0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
