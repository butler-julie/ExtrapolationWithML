#################################################
# Regression Test Code
# Julie Butler Hartley
# Version 1.0.1
# Date Created: July 15, 2020
# Last Modified: August 5, 2020
#
# Code to implement the Linear Regression Analysis, Ridge Regression Analysis,
# and Kernel Ridge Regression Analysis classes and graph the various results.
# Currently only implements for known data functions (regular and sequential)
# with serial hyperparamter tuning.
#################################################

#############################
# IMPORTS
#############################
# SYSTEM LEVEL IMPORTS
# Import files from other directories
import sys

# THIRD-PARTY IMPORTS
# For array handling
import numpy as np

# LOCAL IMPORTS
# Linear regression codes
from LinearRegression import LinearRegressionAnalysis
# Ridge regression codes
from RidgeRegression import RidgeRegressionAnalysis
# Kernel ridge regression codes
from KernelRidgeRegression import KernelRidgeRegressionAnalysis
# Support methods, including graphing capabilities
from RegressionSupport import *
# Data sets (mostly physics related)
from DataSets import *
from ElectronGas import *


#############################
# BOOLEANS FOR REGRESSION ALGORITHM CHOICE
#############################
# True case is to perform that type of regression
isLinearRegression = False
isRidgeRegression = True
isKernelRidgeRegression = False


#############################
# BOOLEANS FOR TRAINING METHOD CHOICE
#############################
# True case is to train the algorith with the listed type of training method
# Regular is the typical training method with points of the form (x,y)
# Sequential is the new method of training where the points are of the form
# ((y1, y2), y3)
isRegularTrain = True
isSequentialTrain = False


#############################
# VERBOSE BOOLEAN
#############################
# True case is to print information about the training and the best model to the
# terminal
isVerbose = True


#############################
# GRAPHING BOOLEANS AND VARIABLES
#############################
# True case produces graphs to compare the regression models and the training
# methods
isGraph = False
# True case saves the created graphs to file
isSave = False
# Prefix for the file names of the saved graphs
graphsavename_prefix = 'Linear'
# True case means that the created graphs are displayed to the screen
isDisplay = False


#############################
# BOOLEANS FOR SAVING RESULTS
#############################
isSaveExtrapolation = True
isSaveParameters = True
savename_prefix = 'VaryInteractionNegative_'

#############################
# COMPLETE DATA SET
#############################
# Complete data set, either imported from the DataSets file or generated through
# Numpy

# IMPORTED DATA SET
data_name, training_dim, X_tot, y_tot = rs_0_1_N_74()
#training_dim = 18
# NUMPY GENERATED DATA SET
#X_tot = np.arange(-1, 1, 0.01)
#y_tot = X_tot
#training_dim = 50



#############################
# LIST TO HOLD ML EXTRAPOLATED DATA SETS
#############################
# Empty lists to hold the best extrapolated data set generated by the best model
# from each algorithm and each training method.  Will remain empty if the chosen
# method and training type are not selected using the above booleans.
lr_reg_data = []
lr_seq_data = []
rr_reg_data = []
rr_seq_data = []
krr_reg_data = []
krr_seq_data = []


#############################
# VARIABLES TO HOLD BEST EXTRAPOLATION ERROR
#############################
# Empty variables to hold the extrapolation error generated by the best model
# from each algorithm and each training method.  Will remain 'None' if the
# chosen method and training type are not selected using the above booleans.
lr_reg_score = None
lr_seq_score = None
rr_reg_score = None
rr_seq_score = None
krr_reg_score = None
krr_seq_score = None


#############################
# EARLY STOPPING THRESHOLD
#############################
# The early stopping threshold for hyperparameter tuning.  Set to 0 if complete
# tuning is required.  Setting the variable 'threshold' to a number means that
# the training process will stop when it produces an extrapolated MSE error
# less than or equal to 'threshold' and will return the model that produced that
# score as the best model.
threshold = 0


#############################
# GENERATE REGULAR TRAINING SET
#############################
# Generating the data set for training algorithms using the regular training
# method.  This just involves splicing off the first nth elements of the total
# data from both X_tot and Y_tot where n is the training dimension defined
# above.
if isRegularTrain:
	X_regular = X_tot[:training_dim].reshape(-1, 1)
	y_regular = y_tot[:training_dim]


#############################
# GENERATE SEQUENTIAL TRAINING SET
#############################
# Generate the data set for training algorithms using the new (sequential)
# training method.  This just involves splicing off the first nth elements of
# the total data from Y_tot where n is the training dimension defined above and
# then formatting the data to follow the ((y1, y2), y3) data pattern.
if isSequentialTrain:
	X_sequential, y_sequential = time_series_data (y_tot[:training_dim])


#############################
# LINEAR REGRESSION PARAMETERS
#############################
# Possible values of parameters for the linear regression algorithm
params_list_lr = [[True, False], [True, False]]


#############################
# RIDGE REGRESSION PARAMETERS
#############################
# Possible values of parameters for the ridge regression algorithm
normalizes = [True, False]
solvers= ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']
alphas = np.logspace(-50, 0, 500)
params_list_rr = [normalizes, alphas, solvers]

#############################
# KERNEL RIDGE REGRESSION PARAMETERS
#############################
# Possible values of parameters for the kernel ridge regression algorithm
kernels = ['polynomial', 'sigmoid']
degrees = [1, 2, 3, 4]
alphas = np.logspace(-20, -10, 20)
coef0s = np.arange(-5, 6, 1)
gammas = np.logspace(-2, 2, 15)
params_list_krr = [kernels, degrees, alphas, coef0s, gammas]
#params_list_krr = [['sigmoid'], [1], [2.06913808111479E-14], [4], [51.794746792312]]

#############################
# LINEAR REGRESSION ANALYSIS
#############################
# Perform linear regression on the data set if needed.
if isLinearRegression:
	# Initialize an pbkect of the linear regression class
	lr = LinearRegressionAnalysis()
	# Train the linear regression algorithm using the regular training method if
	# needed.
	if isRegularTrain:
		best_models_regular = lr.tune_serial_regular (params_list_lr, X_regular,
				y_regular, training_dim, y_tot, verbose=isVerbose,
				isReturnBest = True, threshold = threshold)
		# Save the best extrapolated data set and extrapolated error to variables
		# to be used later
		lr_reg_data = best_models_regular[2]
		lr_reg_score = best_models_regular[0]
		# If needed save the extrapolated data points and the optimized
		# parameters to file.  File format is a .npy Numpy file.
		if isSaveExtrapolation:
			savename = savename_prefix + 'LinearRegressionRegularExtrapolation'
			np.save(savename, lr_reg_data)
		if isSaveParameters:
			savename = savename_prefix + 'LinearRegressionRegularParameters'
			np.save(savename, best_models_regular[1])

	# Train the linear regression algorithm using the new training method if needed.
	if isSequentialTrain:
		best_models_sequential = lr.tune_serial_seq (params_list_lr, X_sequential,
				y_sequential, training_dim, y_tot, verbose=isVerbose,
				isReturnBest = True, threshold = threshold)
		# Save the best extrapolated data set and extrapolated error to variables
		# to be used later
		lr_seq_data = best_models_sequential[2]
		lr_seq_score = best_models_sequential[0]
		# If needed save the extrapolated data points and the optimized
		# parameters to file.  File format is a .npy Numpy file.
		if isSaveExtrapolation:
			savename = savename_prefix + 'LinearRegressionSequentialExtrapolation'
			np.save(savename, lr_seq_data)
		if isSaveParameters:
			savename = savename_prefix + 'LinearRegressionSequentialParameters'
			np.save(savename, best_models_sequential[1])


#############################
# RIDGE REGRESSION ANALYSIS
#############################
# Perform ridge regression on the data set if needed.
if isRidgeRegression:
	# Initialize an instance of the ridge regression class
	rr = RidgeRegressionAnalysis()
	# Train the ridge regression algorithm using the regular training method if needed.
	if isRegularTrain:
		best_models_regular = rr.tune_serial_regular (params_list_rr, X_regular,
				y_regular, training_dim, y_tot, verbose=isVerbose,
				isReturnBest = True, threshold = threshold)
		# Save the best extrapolated data set and extrapolated error to variables
		# to be used later
		rr_reg_data = best_models_regular[2]
		rr_reg_score = best_models_regular[0]
		# If needed save the extrapolated data points and the optimized
		# parameters to file.  File format is a .npy Numpy file.
		if isSaveExtrapolation:
			savename = savename_prefix + 'RidgeRegressionRegularExtrapolation'
			np.save(savename, rr_reg_data)
		if isSaveParameters:
			savename = savename_prefix + 'RidgeRegressionRegularParameters'
			np.save(savename, best_models_regular[1])

	# Train the ridge regression algorithm using the new training method if needed.
	if isSequentialTrain:
		best_models_sequential = rr.tune_serial_seq (params_list_rr, X_sequential,
				y_sequential, training_dim, y_tot, verbose=isVerbose,
				isReturnBest = True, threshold = threshold)
		# Save the best extrapolated data set and extrapolated error to variables
		# to be used later
		rr_seq_data = best_models_sequential[2]
		rr_seq_score = best_models_sequential[0]
		# If needed save the extrapolated data points and the optimized
		# parameters to file.  File format is a .npy Numpy file.
		if isSaveExtrapolation:
			savename = savename_prefix + 'RidgeRegressionRegularExtrapolation'
			np.save(savename, rr_seq_data)
		if isSaveParameters:
			savename = savename_prefix + 'RidgeRegressionRegularParameters'
			np.save(savename, best_models_sequential[1])


#############################
# KERNEL RIDGE REGRESSION ANALYSIS
#############################
# Perform kernel ridge regression on the data set if needed.
if isKernelRidgeRegression:
	# Initialize the kernel ridge regression class
	krr = KernelRidgeRegressionAnalysis()
	# Train the kernel ridge regression algorithm using the regular training method if
	# needed.
	if isRegularTrain:
		best_models_regular = krr.tune_serial_regular (params_list_krr, X_regular,
		 		y_regular, training_dim, y_tot, verbose=isVerbose,
				isReturnBest = True, threshold = threshold)
		# Save the best extrapolated data set and extrapolated error to variables
		# to be used later
		krr_reg_data = best_models_regular[2]
		krr_reg_score = best_models_regular[0]
		# If needed save the extrapolated data points and the optimized
		# parameters to file.  File format is a .npy Numpy file.
		if isSaveExtrapolation:
			savename = savename_prefix + 'KernelRidgeRegressionRegularExtrapolation'
			np.save(savename, krr_reg_data)
		if isSaveParameters:
			savename = savename_prefix + 'KernelRidgeRegressionRegularParameters'
			np.save(savename, best_models_regular[1])

	# Train the kernel ridge regression algorithm using the new training method if needed.
	if isSequentialTrain:
		best_models_sequential = krr.tune_serial_seq (params_list_krr,
				X_sequential, y_sequential, training_dim, y_tot,
				verbose=isVerbose, isReturnBest = True, threshold = threshold)
		# Save the best extrapolated data set and extrapolated error to variables
		# to be used later
		krr_seq_data = best_models_sequential[2]
		krr_seq_score = best_models_sequential[0]
		# If needed save the extrapolated data points and the optimized
		# parameters to file.  File format is a .npy Numpy file.
		if isSaveExtrapolation:
			savename = savename_prefix + 'KernelRidgeRegressionRegularExtrapolation'
			np.save(savename, krr_seq_data)
		if isSaveParameters:
			savename = savename_prefix + 'KernelRidgeRegressionRegularParameters'
			np.save(savename, best_models_sequential[1])


#############################
# GRAPHING
#############################
# If training was performed with the regular method and the results need to be
# graphed.  Check in place to ensure the linear regression and ridge regression
# algoritms converged with regular format training.
if isRegularTrain and isGraph and lr_reg_data and rr_reg_data:
	savename = graphsavename_prefix + 'RegularTrain.pdf'
	graph_LR_RR_KRR (X_tot, y_tot, isKernelRidgeRegression, krr_reg_data,
		isRidgeRegression, rr_reg_data, isLinearRegression, lr_reg_data, isSave,
		savename, isDisplay)

# If training was performed with the sequentual method and the results need to
# be graphed
if isSequentialTrain and isGraph:
	savename = graphsavename_prefix + 'SequentialTrain.pdf'
	graph_LR_RR_KRR (X_tot, y_tot, isKernelRidgeRegression, krr_seq_data,
		isRidgeRegression, rr_seq_data, isLinearRegression, lr_seq_data, isSave,
		savename, isDisplay)

# If linear regression was performed and the results need to be graphed.  Check
# in place to make sure the regular training format converged.
if isLinearRegression and isGraph and lr_reg_data:
	savename = graphsavename_prefix + 'LinearRegression.pdf'
	graph_reg_vs_seq (X_tot, y_tot, isRegularTrain, lr_reg_data,
			isSequentialTrain, lr_seq_data, isSave, savename, isDisplay)

# If ridge regression was performed and the results need to be graphed.  Check
# in place to make sure the regular training format converged.
if isRidgeRegression and isGraph and rr_reg_data:
	savename = graphsavename_prefix + 'RidgeRegression.pdf'
	graph_reg_vs_seq (X_tot, y_tot, isRegularTrain, rr_reg_data,
			isSequentialTrain, rr_seq_data, isSave, savename, isDisplay)

# If kernel ridge regression was performed and the results need to be graphed.
if isKernelRidgeRegression and isGraph and krr_reg_data:
	savename = graphsavename_prefix + 'KernelRidgeRegression.pdf'
	graph_reg_vs_seq (X_tot, y_tot, isRegularTrain, krr_reg_data,
			isSequentialTrain, krr_seq_data, isSave, savename, isDisplay)
