{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Regression Example\n",
    "\n",
    "Julie Butler Hartley\n",
    "\n",
    "Version 1.0.0\n",
    "\n",
    "Date Created: October 28, 2020\n",
    "\n",
    "Last Modified: October 28, 2020\n",
    "\n",
    "The following notebook demonstrates the abilities of linear regression, ridge regression, and kernel ridge regression to extrapolate data using sequential (time-series formatting).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.linear_model.ridge module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SYSTEM LEVEL IMPORTS\n",
    "# Import files from other directories\n",
    "import sys\n",
    "\n",
    "# THIRD-PARTY IMPORTS\n",
    "# For array handling\n",
    "import numpy as np\n",
    "# Linear Ridge Method\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Ridge Methods\n",
    "from sklearn.linear_model.ridge import Ridge\n",
    "# Kernel Ridge Methods\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "# Prevents extraneous printing of messages during a grid search\n",
    "import warnings\n",
    "# For graphing \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LOCAL IMPORTS\n",
    "# Changing the import directory\n",
    "sys.path.append('../DataSets/')\n",
    "# Data sets (mostly physics related)\n",
    "from DataSets import *\n",
    "from ElectronGas import *\n",
    "from NuclearBindingEnergy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting the Data\n",
    "\n",
    "The way the regression algorithms are trained in this program differs from how machine learning algorithms are usually trained, but is similar to a training method typically only done on recurrent neural networks.  Typically a machine learning algorithm is trained by learning the relationship between the x data and the y data.  In this program, the recurrent neural network will be trained to recognize the relationship in a sequence of y values.  This is type of data formatting is typically used time series forcasting, but it can also be used in any extrapolation (time series forecasting is just a specific type of extrapolation along the time axis).  This method of data formatting does not use the x data and assumes that the y data are evenly spaced.\n",
    "\n",
    "For a standard machine learning algorithm, the training data has the form of (x,y) so the machine learning algorithm learns to assiciate a y value with a given x value.  This is useful when the test data has x values within the same range as the training data.  However, for this application, the x values of the test data are outside of the x values of the training data and the traditional method of training a machine learning algorithm does not work as well.  For this reason, the recurrent neural network is trained on sequences of y values of the form ((y1, y2), y3), so that the network is concerned with learning the pattern of the y data and not the relation between the x and y data.  As long as the pattern of y data outside of the training region stays relatively stable compared to what was inside the training region, this method of training can produce accurate extrapolations to y values far removed from the training data set.\n",
    "\n",
    "The idea behind formatting the data in this way comes from [this resource](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/) and [this one](https://fairyonice.github.io/Understand-Keras%27s-RNN-behind-the-scenes-with-a-sin-wave-example.html).\n",
    "\n",
    "The following method takes in a y data set and formats it so the \"x data\" are of the form (y1, y2) and the \"y data\" are of the form y3, with extra brackets added in to make the resulting arrays compatable with both Keras and Tensorflow.\n",
    "\n",
    "Note: Using a sequence length of two is not required for time series forecasting so any lenght of sequence could be used (for example instead of ((y1, y2) y3) you could change the length of sequence to be 4 and the resulting data points would have the form ((y1, y2, y3, y4), y5)).  While the following method can be used to create a data set of any sequence length, the remainder of the code expects the length of sequence to be 2.  This is because the data sets are very small and the higher the lenght of the sequence the less resulting data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data, length_of_sequence = 2):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            data(a numpy array): the data that will be the inputs to the recurrent neural\n",
    "                network\n",
    "            length_of_sequence (an int): the number of elements in one iteration of the\n",
    "                sequence patter.  For a function approximator use length_of_sequence = 2.\n",
    "        Returns:\n",
    "            rnn_input (a 2D numpy array): the input data for the regression.\n",
    "            rnn_output (a numpy array): the training data for the regression\n",
    "        Formats data in a time series-inspired way to be used in ridge and kernel ridge\n",
    "        regression.\n",
    "        NOTE: formally format_data_dnn from RNN codes.\n",
    "    \"\"\"\n",
    "    # Lists to hold the formatted data\n",
    "    inputs, outputs = [], []\n",
    "    # Loop through the data\n",
    "    for i in range(len(data)-length_of_sequence):\n",
    "        # Get the next length_of_sequence elements\n",
    "        a = data[i:i+length_of_sequence]\n",
    "        # Get the element that immediately follows that\n",
    "        b = data[i+length_of_sequence]\n",
    "        # Add new points to the returned arrays\n",
    "        inputs.append(a)\n",
    "        outputs.append(b)\n",
    "    # Format the lists as numpy arrays\n",
    "    inputs = np.array(inputs)\n",
    "    outputs = np.array(outputs)\n",
    "    # Return the two formatted arrays\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean-Squared Error Function\n",
    "A quick mean-squared error function that will be used later in the regression functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse (A, B):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            A, B (numpy arrays of the same length): two different data sets\n",
    "        Returns:\n",
    "            Unnamed (a float): the mean-squared error score between data sets A and B\n",
    "        Finds the mean-squared error of the two data sets given as inputs.\n",
    "    \"\"\"\n",
    "    return ((A-B)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Algorithms\n",
    "\n",
    "The following three functions each create a linear regression algorithm, a ridge regression algorithm, or a kernel ridge regression algorithm (in that order) using the machine learning package Scikit-Learn.  Each function trains the algorithms using training data in the sequential data format, and the uses the trained algorithm to predict further points in the data set.  These functions assumes the complete, true data set is known and performs an analysis to see how closesly the predicted data set matches the true data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Linear regression (LR) is a machine learning model which performs\n",
    "regression analysis on a data set to find a line which best models the\n",
    "data.  Ridge regression (RR) and kernel ridge regression (KRR) are\n",
    "machine learning models that stem from the simple linear regression\n",
    "model.  The loss function for the linear regression algorithm can be\n",
    "written as:\n",
    "\n",
    "$$J(\\textbf{w}) = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 .$$\n",
    "\n",
    "In the above equation, the vector \\textbf{y} is the \"true\" data or the\n",
    "y-values from the training data set, and the vector $\\hat{\\textbf{y}}$\n",
    "is the data generated by the linear regression algorithm.\n",
    "$\\hat{\\textbf{y}}$ can also be written as:\n",
    "\n",
    "$$\\hat{\\textbf{y}} = \\textbf{x}w ,$$\n",
    "\n",
    "where $\\textbf{x}$ are the x-values of the training data and w is a\n",
    "matrix of weights that are optimized to minimize the loss function\n",
    "given in Equation (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression (X_train, y_train, y_tot, training_dim, params,\n",
    "    verbose=True, seq=2):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            X_train (a list or numpy array): the x component of the training data\n",
    "            y_train (a list or numpy array): the y component of the training data\n",
    "            y_tot (a list of numpy array): the total set of data points (training plus validation)\n",
    "            training_dim (an int): the size of the traing data (i.e. the number of points\n",
    "                from y_tot that are used in the training)\n",
    "            params (a list): contains the parameters of the linear regression\n",
    "                algorithm.  In order: fit intercept and normalize.\n",
    "            verbose (a boolean): True case: prints the MSE score of the extrapolated data\n",
    "                when compared to the true data.\n",
    "        Returns:\n",
    "            y_return (a list): the known points and the extrapolated data points\n",
    "            Unnamed (a float): the MSE error between the true data and the predicted\n",
    "                data\n",
    "        Performs linear regression on the given data set using the given parameters\n",
    "        and then extrapolates data points to get a complete data set.  Prints the MSE\n",
    "        score of the extrapolated data set compared to the true data set if desired and\n",
    "        then returns the extrapolated data set.\n",
    "    \"\"\"\n",
    "    # To ensure that all parameters are present\n",
    "    assert len(params)==2\n",
    "\n",
    "    # Set up the model\n",
    "    lr = LinearRegression (fit_intercept = params[0], normalize = params[1])\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict the points in the validation set\n",
    "    y_return = y_tot[:training_dim].tolist()\n",
    "    next_input = [[y_return[-2], y_return[-1]]]\n",
    "    last = y_return[-1]\n",
    "    while len(y_return) < len(y_tot):\n",
    "        try:\n",
    "            next = lr.predict(next_input)\n",
    "        except:\n",
    "            print ('Overflow encountered on predicton')\n",
    "            return None, 1e10\n",
    "        y_return.append(next[0])\n",
    "        next_input =[[last, next[0]]]\n",
    "        last = next[0]\n",
    "\n",
    "    # Print the MSE error if needed\n",
    "    if verbose:\n",
    "        print ('LINEAR REGRESSION MSE VALUE: ', mse(y_tot, y_return))\n",
    "\n",
    "    # Return the predicted points and the MSE error\n",
    "    return y_return, mse(y_tot, y_return)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "\n",
    "Using the loss function for the linear regression model, the loss function for the ridge regression model can be easily written by adding an extra, regularization term.\n",
    "\n",
    "$$J(\\textbf{w}) = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + \\alpha\\sum_{i=1}^n w_i^2 ,$$\n",
    "\n",
    "where $\\textbf{y}$ and $\\hat{\\textbf{y}}$ are defined in the same way as\n",
    "for linear regression.  This equation differs from Equation (1) by the\n",
    "inclusion of the regularization term at the end. This term introduces\n",
    "a small amount of bias into the algorithm, leading to a large drop in\n",
    "the variance (bias-variance trade-off), allowing the ridge regression\n",
    "algorithm to generalize to new data points better than regular linear\n",
    "regression.  The term $\\alpha$ is a hyperparameter which controls how\n",
    "much bias is introduced into the algorithm (a larger value of $\\alpha$\n",
    "means more bias is added in). This second term is a regularization\n",
    "term and therefore $\\alpha$ can also be referred to as the strength of\n",
    "the regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X_train, y_train, y_tot, training_dim, params, verbose=True, seq=2):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            X_train (a list or numpy array): the x component of the training data\n",
    "            y_train (a list or numpy array): the y component of the training data\n",
    "            y_tot (a list of numpy array): the total set of data points (training plus validation)\n",
    "            training_dim (an int): the size of the traing data (i.e. the number of points\n",
    "                from y_tot that are used in the training)\n",
    "            params (a list): contains the parameters of the ridge regression \n",
    "                algorithm.  In order: normalize, alpha, and solver.\n",
    "            verbose (a boolean): True case: prints the MSE score of the extrapolated data\n",
    "                when compared to the true data.\n",
    "        Returns:\n",
    "            y_return (a list): the known points and the extrapolated data points\n",
    "            Unnamed (a float): the MSE error between the true data and the predicted\n",
    "                data\n",
    "        Performs ridge regression on the given data set using the given parameters\n",
    "        and then extrapolates data points to get a complete data set.  Prints the MSE \n",
    "        score of the extrapolated data set compared to the true data set if desired and\n",
    "        then returns the extrapolated data set.\n",
    "\n",
    "    \"\"\"\n",
    "    # To ensure that all parameters are present \n",
    "    assert len(params)==3\n",
    "\n",
    "    # Set up the model\n",
    "    r = Ridge (normalize = params[0], alpha = params[1], solver = params[2])    \n",
    "\n",
    "    # Fit the model to the training data\n",
    "    r.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict the points in the validation set\n",
    "    y_return = y_tot[:training_dim].tolist()\n",
    "    next_input = [[y_return[-2], y_return[-1]]]\n",
    "    last = y_return[-1]\n",
    "    while len(y_return) < len(y_tot):\n",
    "        try:\n",
    "            next = r.predict(next_input)\n",
    "        except:\n",
    "            print ('Overflow encountered on predicton')\n",
    "            return None, 1e10\n",
    "        y_return.append(next[0])\n",
    "        next_input =[[last, next[0]]]\n",
    "        last = next[0]\n",
    "\n",
    "    # Print the MSE error if needed\n",
    "    if verbose:  \n",
    "        print ('RIDGE MSE VALUE: ', mse(y_tot, y_return))\n",
    "\n",
    "    # Return the predicted points and the MSE error\n",
    "    return y_return, mse(y_tot, y_return)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression\n",
    "\n",
    "The loss function for kernel ridge regression is the same as the loss\n",
    "function for ridge regression (with the inclusion of the\n",
    "regularization term), but the output of the model, $\\hat{\\textbf{y}}$,\n",
    "changes for kernel ridge regression. For kernel ridge regression,\n",
    "$\\hat{\\textbf{y}}$ is defined as:\n",
    "\n",
    "$$\\hat{\\textbf{y}} = -\\frac{1}{\\alpha}\\sum_{i=1}^n \\gamma_ik(\\textbf{x}, \\textbf{x}_i)$$\n",
    "\n",
    "\n",
    "There are several popular kernels which are commonly used in kernel ridge regression.  They are listed in Table 1 along with their mathematical expressions.  Note that the linear kernel is just a special case of the polynomial kernel.\n",
    "        \n",
    "| Kernel| Mathematical Expression |\n",
    "|------|------|\n",
    "| Polynomial | k(x,y) = ($\\gamma$x$^T$y + c$_0$)$^d$ | \n",
    "| Linear | k(x,y) = x$^T$y | \n",
    "| Sigmoid | k(x,y) = tanh($\\gamma$x$^T$y + c$_0$) | \n",
    "| Radial Basis Function | k(x,y) = tanh($\\gamma$x$^T$y + c$_0$) | \n",
    "|Laplacian | k(x,y) = tanh($\\gamma$x$^T$y + c$_0$) | \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_ridge_regression (X_train, y_train, y_tot, training_dim, params, verbose=True, seq=2):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            X_train (a list or numpy array): the x component of the training data\n",
    "            y_train (a list or numpy array): the y component of the training data\n",
    "            y_tot (a list of numpy array): the total set of data points (training plus validation)\n",
    "            training_dim (an int): the size of the traing data (i.e. the number of points\n",
    "                from y_tot that are used in the training)\n",
    "            params (a list): contains the parameters of the kernel ridge regression \n",
    "                algorithm.  In order: kernel, degree, alpha, coef0, gamma.\n",
    "            verbose (a boolean): True case: prints the MSE score of the extrapolated data\n",
    "                when compared to the true data.\n",
    "        Returns:\n",
    "            y_return (a list): the known points and the extrapolated data points\n",
    "            Unnamed (a float): the MSE error between the true data and the predicted\n",
    "                data\n",
    "        Performs kernel ridge regression on the given data set using the given parameters\n",
    "        and then extrapolates data points to get a complete data set.  Prints the MSE \n",
    "        score of the extrapolated data set compared to the true data set if desired and\n",
    "        then returns the extrapolated data set.\n",
    "\n",
    "    \"\"\"\n",
    "    # To ensure that all parameters are present \n",
    "    assert len(params)==5\n",
    "\n",
    "    # Set up the model\n",
    "    kr = KernelRidge (kernel=params[0], degree=params[1], alpha=params[2], coef0=params[3], gamma=params[4])    \n",
    "\n",
    "    # Fit the model to the training data\n",
    "    kr.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict the points in the validation set\n",
    "    y_return = y_tot[:training_dim].tolist()\n",
    "    next_input = [[y_return[-2], y_return[-1]]]\n",
    "    last = y_return[-1]\n",
    "    while len(y_return) < len(y_tot):\n",
    "        try:\n",
    "            next = kr.predict(next_input)\n",
    "        except:\n",
    "            print ('Overflow encountered on predicton')\n",
    "            return None, 1e10\n",
    "        y_return.append(next[0])\n",
    "        next_input =[[last, next[0]]]\n",
    "        last = next[0]\n",
    "\n",
    "    # Print the MSE error if needed\n",
    "    if verbose:  \n",
    "        print ('KERNEL RIDGE MSE VALUE: ', mse(y_tot, y_return))\n",
    "\n",
    "    # Return the predicted points and the MSE error\n",
    "    return y_return, mse(y_tot, y_return)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Regression Algorithms\n",
    "\n",
    "The following code test the ability of all three regression algorithms to extrapolate points in a data set outside of the training region.  In this case the data of interest is taken from an Couple Cluster/Electron gas data set (located in the DataSets folder), but this code could be easily modified to work with any data set.\n",
    "\n",
    "The code uses parameters which are optimized to the data set and were found using hyperparameter tuning (see the file RegressionTestCode.py).  The code trains all three types of linear regression algorithms using some subset of the complete data set and then extrapolates to a complete data set.  All three extrapolated data sets are then plotted against the known data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR REGRESSION MSE VALUE:  9.993527678548828e-06\n",
      "RIDGE MSE VALUE:  1.0815091622545033e-05\n",
      "KERNEL RIDGE MSE VALUE:  1.721755163600999e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.7/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12741ed68>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the data set\n",
    "name, dim, X_tot, y_tot, N = rs_1_N_26 ()\n",
    "\n",
    "# Create a training data set by applying sequential formatting to the first dim points\n",
    "# of the y data\n",
    "X_train, y_train = format_data(y_tot[:dim])\n",
    "\n",
    "# Optimized parameters found through hyperparameter tuning\n",
    "# These parameters are (in order): Normalize, Set Intercept\n",
    "params_lr = [True, True]\n",
    "# These parameters are (in order): Normalize, alpha, solver\n",
    "params_rr = [False, 1.175277E-15,'sag']\n",
    "# These parameters are (in order): kernel, degree (N/A), alpha, coef0 (N/A), gamma\n",
    "# Note that degree and coef0 are not taken into account when using the sigmoid kernel\n",
    "params_krr = ['sigmoid', 1.00, 7.847600E-13, 5.00, 1.389495E+01]\n",
    "\n",
    "# Train all three regression algorithms and use each to extrapolate to a complete data set\n",
    "y_lr, mse_lr = linear_regression (X_train, y_train, y_tot, dim, params_lr, verbose=True, seq=2)\n",
    "y_rr, mse_rr = ridge_regression (X_train, y_train, y_tot, dim, params_rr, verbose=True, seq=2)\n",
    "y_krr, mse_krr = kernel_ridge_regression (X_train, y_train, y_tot, dim, params_krr, verbose=True, seq=2)\n",
    "\n",
    "# Plot the three extrapolated data sets against the true data\n",
    "plt.plot(X_tot, y_lr, label='Linear Regression')\n",
    "plt.plot(X_tot, y_rr, label='Ridge Regression')\n",
    "plt.plot(X_tot, y_krr, label='Kernel Ridge Regression')\n",
    "plt.plot(X_tot, y_tot, label='True Data')\n",
    "\n",
    "# Add axes labels and a legend\n",
    "plt.xlabel('Number of Orbitals')\n",
    "plt.ylabel('Correlation Energy')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
